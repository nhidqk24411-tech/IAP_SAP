# gemini_analyzer.py - Gemini API (google.genai) + quota-aware fallback
# Optimized for flexible, mentor-style, XAI responses (no data repetition)

import sys
import os
from datetime import datetime
from typing import Dict, Any

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from config import Config


class GeminiAnalyzer:
    """Ph√¢n t√≠ch v·ªõi Gemini AI - ∆Øu ti√™n model ch∆∞a deprecate + quota cao"""

    # ------------------------------------------------------------------
    # Danh s√°ch model c√≤n hi·ªáu l·ª±c (ch∆∞a t·ªõi h·∫°n deprecation)
    VALID_MODELS = [
        "gemini-3-flash-preview",
        "gemini-3-pro-preview",
        "gemini-2.5-flash",
        "gemini-2.5-flash-lite",
        "gemini-2.5-pro",
        "gemini-2.0-flash",
        "gemini-2.0-flash-lite",
    ]

    # Heuristic quota priority (cao ‚Üí th·∫•p)
    QUOTA_WEIGHT = {
        "flash-lite": 4,
        "flash": 3,
        "pro": 2,
        "preview": 1,
    }

    def __init__(self):
        self.genai_client = None
        self.active_model = None
        self.use_demo_mode = True
        self.api_type = "DEMO"

        print("üöÄ Kh·ªüi t·∫°o Gemini Analyzer...")

        if not Config.GEMINI_API_KEY or Config.GEMINI_API_KEY in ("", "YOUR_API_KEY_HERE"):
            print("‚ö†Ô∏è Kh√¥ng c√≥ API Key, DEMO mode")
            return

        try:
            from google import genai
            self.genai_client = genai.Client(api_key=Config.GEMINI_API_KEY)
            self.find_best_model()

            if not self.use_demo_mode:
                print(f"‚úÖ D√πng model: {self.active_model}")
            else:
                print("‚ö†Ô∏è Kh√¥ng c√≥ model ph√π h·ª£p, DEMO")

        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o Gemini: {e}")

    # ------------------------------------------------------------------

    def model_weight(self, name: str) -> int:
        name = name.lower()
        for key, w in self.QUOTA_WEIGHT.items():
            if key in name:
                return w
        return 0

    def find_best_model(self):
        """Ch·ªçn model ch∆∞a deprecate + quota cao nh·∫•t"""
        try:
            models = list(self.genai_client.models.list())
            available = []

            for m in models:
                short = m.name.split("/")[-1]
                if short in self.VALID_MODELS:
                    available.append(short)

            if not available:
                return

            available.sort(key=self.model_weight, reverse=True)

            self.active_model = available[0]
            self.use_demo_mode = False
            self.api_type = "API"

            print("üìä Model kh·∫£ d·ª•ng (theo quota):")
            for m in available:
                print(f"  - {m} (w={self.model_weight(m)})")

        except Exception as e:
            print(f"‚ùå L·ªói ch·ªçn model: {e}")

    # ------------------------------------------------------------------

    def analyze_question(self, question: str, context_data: Dict[str, Any]) -> str:
        if self.use_demo_mode:
            return self.get_demo_response(question, context_data)

        prompt = self.create_smart_prompt(question, context_data)

        models_to_try = sorted(
            self.VALID_MODELS,
            key=self.model_weight,
            reverse=True
        )

        for model in models_to_try:
            try:
                print(f"üì§ G·ª≠i {model}")
                response = self.genai_client.models.generate_content(
                    model=model,
                    contents=prompt
                )

                text = response.text or ""
                self.active_model = model
                return self.format_response(text, question)

            except Exception as e:
                if self.is_quota_error(e):
                    print(f"‚ö†Ô∏è {model} h·∫øt quota ‚Üí th·ª≠ model kh√°c")
                    continue
                print(f"‚ùå L·ªói {model}: {e}")
                break

        return self.get_demo_response(question, context_data)

    # ------------------------------------------------------------------

    def is_quota_error(self, e: Exception) -> bool:
        return any(k in str(e).lower() for k in ["quota", "429", "resource_exhausted"])

    # ------------------------------------------------------------------
    # XAI + Career Coach Prompt
    def create_smart_prompt(self, question: str, context_data: Dict) -> str:
        insights = self.extract_insights(context_data)

        return f"""
B·∫°n l√† c·ªë v·∫•n ngh·ªÅ nghi·ªáp v√† hi·ªáu su·∫•t l√†m vi·ªác t·∫°i PowerSight.
Nhi·ªám v·ª• c·ªßa b·∫°n l√† gi√∫p nh√¢n vi√™n hi·ªÉu r√µ nguy√™n nh√¢n v·∫•n ƒë·ªÅ, c·∫£i thi·ªán k·ªπ nƒÉng v√† ph√°t tri·ªÉn s·ª± nghi·ªáp.

Quy t·∫Øc b·∫Øt bu·ªôc:
- Kh√¥ng l·∫∑p l·∫°i d·ªØ li·ªáu th√¥ nh∆∞ work_log, SAP, metrics
- Kh√¥ng li·ªát k√™ s·ªë li·ªáu n·∫øu kh√¥ng th·ª±c s·ª± c·∫ßn thi·∫øt
- Ch·ªâ d√πng d·ªØ li·ªáu ƒë·ªÉ gi·∫£i th√≠ch l√Ω do k·∫øt lu·∫≠n
- Tr·∫£ l·ªùi linh ho·∫°t theo ƒë√∫ng c√¢u h·ªèi c·ªßa nh√¢n vi√™n

T√≥m t·∫Øt c√°c t√≠n hi·ªáu quan tr·ªçng (ƒë√£ ƒë∆∞·ª£c h·ªá th·ªëng ph√¢n t√≠ch):
{insights}

C√¢u h·ªèi c·ªßa nh√¢n vi√™n:
{question}

Y√™u c·∫ßu tr·∫£ l·ªùi theo h∆∞·ªõng gi·∫£i th√≠ch r√µ r√†ng (XAI):
1. Nh·∫≠n ƒë·ªãnh ch√≠nh, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ
2. V√¨ sao ƒë∆∞a ra nh·∫≠n ƒë·ªãnh n√†y (d·ª±a tr√™n t√≠n hi·ªáu n√†o)
3. Y·∫øu t·ªë n√†o ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t v√† y·∫øu nh·∫•t
4. R·ªßi ro ngh·ªÅ nghi·ªáp n·∫øu kh√¥ng c·∫£i thi·ªán
5. L·ªùi khuy√™n th·ª±c t·∫ø, c√≥ th·ªÉ √°p d·ª•ng trong 1‚Äì2 tu·∫ßn t·ªõi

VƒÉn phong:
- Nh∆∞ ng∆∞·ªùi c·ªë v·∫•n
- T√≠ch c·ª±c, th·ª±c t·∫ø
- Kh√¥ng ph√°n x√©t
- Ti·∫øng Vi·ªát
"""

    # ------------------------------------------------------------------
    # XAI Insight Extractor (core logic)
    def extract_insights(self, data: Dict[str, Any]) -> str:
        insights = []

        wl = data.get("work_log", {})
        sap = data.get("sap_data", {})
        m = data.get("metrics", {})

        if wl:
            if wl.get("error_count", 0) > 5:
                insights.append("C√≥ sai s√≥t l·∫∑p l·∫°i trong qu√° tr√¨nh l√†m vi·ªác, ·∫£nh h∆∞·ªüng cao.")
            if wl.get("warning_count", 0) > 3:
                insights.append("Quy tr√¨nh l√†m vi·ªác ch∆∞a ·ªïn ƒë·ªãnh, ·∫£nh h∆∞·ªüng trung b√¨nh.")
            if wl.get("fraud_count", 0) > 0:
                insights.append("C√≥ d·∫•u hi·ªáu h√†nh vi b·∫•t th∆∞·ªùng, ·∫£nh h∆∞·ªüng r·∫•t cao.")

        if sap:
            if sap.get("completion_rate", 100) < 80:
                insights.append("T·ª∑ l·ªá ho√†n th√†nh c√¥ng vi·ªác th·∫•p h∆°n k·ª≥ v·ªçng, ·∫£nh h∆∞·ªüng cao.")
            if sap.get("profit", 0) < 0:
                insights.append("Hi·ªáu qu·∫£ t√†i ch√≠nh ch∆∞a t·ªët, ·∫£nh h∆∞·ªüng trung b√¨nh.")

        if m:
            if m.get("efficiency", 100) < 60:
                insights.append("Hi·ªáu su·∫•t l√†m vi·ªác th·∫•p so v·ªõi chu·∫©n, ·∫£nh h∆∞·ªüng cao.")
            if m.get("quality", 100) < 70:
                insights.append("Ch·∫•t l∆∞·ª£ng c√¥ng vi·ªác ch∆∞a ·ªïn ƒë·ªãnh, ·∫£nh h∆∞·ªüng trung b√¨nh.")
            if m.get("compliance", 100) < 80:
                insights.append("M·ª©c ƒë·ªô tu√¢n th·ªß quy tr√¨nh ch∆∞a t·ªët, ·∫£nh h∆∞·ªüng trung b√¨nh.")

        if not insights:
            return "Hi·ªáu su·∫•t t·ªïng th·ªÉ ·ªïn ƒë·ªãnh, ch∆∞a th·∫•y r·ªßi ro ƒë√°ng k·ªÉ."

        return "- " + "\n- ".join(insights)

    # ------------------------------------------------------------------

    def format_response(self, response: str, question: str) -> str:
        return (
            "ü§ñ POWER SIGHT AI\n"
            f"üß† Model: {self.active_model}\n"
            f"‚è∞ {datetime.now():%d/%m/%Y %H:%M}\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"C√¢u h·ªèi: {question}\n\n"
            f"{response}"
        )

    def get_demo_response(self, question: str, context_data: Dict) -> str:
        return self.format_response(
            "DEMO MODE ‚Äì H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh API h·ª£p l·ªá.",
            question
        )
